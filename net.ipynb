{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from IPython import display\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "root = Path(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 8, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(8, 16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv1d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2))\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(2048, 2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.output(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class predictdataset:\n",
    "    def __init__(self, directory):\n",
    "        self.directory = directory\n",
    "        self.index = str(directory)[-3:]\n",
    "        self.filepaths = [directory / file for file in os.listdir(directory) if \".tif\" in file][:512]\n",
    "        self.imagetensors = {file: transforms.ToTensor()(ImageOps.autocontrast(Image.open(file).convert('L').resize((256, 256)))).cuda().squeeze() \\\n",
    "                             for file in self.filepaths}\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    def tensor(self, coordinates):\n",
    "        data = torch.zeros((1, 1, 512), device=self.device)\n",
    "        for t, file in enumerate(self.filepaths):\n",
    "            data[0, 0, t] = self.imagetensors[file][coordinates]\n",
    "        data[0,0,:] = data[0,0,:]/torch.max(data).item()\n",
    "        data.requires_grad_(True)\n",
    "        return data\n",
    "\n",
    "class realdataset:\n",
    "    def __init__(self, directory):\n",
    "        self.directory = directory\n",
    "        self.index = str(directory)[-3:]\n",
    "        self.filepaths = [directory / file for file in os.listdir(directory) if \".tif\" in file][:512]\n",
    "        self.imagetensors = {file: transforms.ToTensor()(ImageOps.autocontrast(Image.open(file).convert('L').resize((256,256)))).cuda().squeeze() \\\n",
    "                             for file in self.filepaths}\n",
    "        self.ground_truth = np.loadtxt(directory / \"..\" / \"..\" / \"output\" / self.index / \"indices.txt\", dtype=float)\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    def positives(self):\n",
    "        return list(zip(np.where(self.ground_truth!=0)[0], np.where(self.ground_truth!=0)[1]))\n",
    "    def controls(self):\n",
    "        total = np.shape(self.ground_truth)[0]*np.shape(self.ground_truth)[1]\n",
    "        negative_count = np.shape(self.ground_truth[np.where(self.ground_truth==0)])[0]\n",
    "        positive_count = total-negative_count\n",
    "        negatives = list(zip(np.where(self.ground_truth==0)[0], np.where(self.ground_truth==0)[1]))\n",
    "        picked_negatives = random.sample(negatives, positive_count)\n",
    "        return picked_negatives\n",
    "    def tensor(self, p, coordinates):\n",
    "        labels = torch.zeros(1, dtype=torch.int64, device=self.device)\n",
    "        labels[0] = 1 if p==1 else 0\n",
    "        data = torch.zeros((1, 1, 512), device=self.device)\n",
    "        for t, file in enumerate(self.filepaths):\n",
    "            data[0, 0, t] = self.imagetensors[file][coordinates]\n",
    "        data[0,0,:] = data[0,0,:]/torch.max(data).item()\n",
    "        data.requires_grad_(True)\n",
    "        return labels, data\n",
    "    \n",
    "class synthdataset:\n",
    "    def __init__(self, directory):\n",
    "        self.directory = directory\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.positives = [directory / \"positives\" / file for file in os.listdir(directory / \"positives\")]\n",
    "        self.negatives = [directory / \"negatives\" / file for file in os.listdir(directory / \"negatives\")]\n",
    "        self.all = list(zip([1 for _ in self.positives]+[0 for _ in self.negatives], self.positives+self.negatives))\n",
    "        self.time = 512\n",
    "        self.allshuffle = random.sample(self.all, len(self.all))\n",
    "    def load(self, file):\n",
    "        return np.loadtxt(file, dtype=float)\n",
    "    def tensor(self, p, file):\n",
    "        label = torch.zeros(1, dtype=torch.int64, device=self.device)\n",
    "        label[0] = 1 if p==1 else 0\n",
    "        data = torch.zeros(self.time, device=self.device)\n",
    "        npdata = self.load(file)\n",
    "        for t in range(self.time):\n",
    "            data[t] = npdata[t]\n",
    "        data.requires_grad_(True)\n",
    "        return label, data\n",
    "    def create_batch(self, batch_size):\n",
    "        assert len(self.allshuffle)%batch_size==0\n",
    "        n_used = 0\n",
    "        def gen_batch():\n",
    "            nonlocal n_used\n",
    "            if n_used == len(self.allshuffle):\n",
    "                return None\n",
    "            else:\n",
    "                labels = torch.stack([self.tensor(p, coordinate)[0] for p,coordinate in self.allshuffle[n_used:n_used+batch_size]])\n",
    "                inputs = torch.stack([self.tensor(p, coordinate)[1] for p,coordinate in self.allshuffle[n_used:n_used+batch_size]])\n",
    "                inputs = inputs[:, None, :]\n",
    "                n_used += batch_size\n",
    "                return labels, inputs\n",
    "        return gen_batch\n",
    "    \n",
    "def batch_accuracy(outputs, labels):\n",
    "    probabilities = torch.nn.Softmax(1)(outputs)\n",
    "    scores = []\n",
    "    for i, index in enumerate(labels):\n",
    "        scores += [probabilities[i, index.item()].item()]\n",
    "    return np.mean(scores)\n",
    "\n",
    "def accuracy(outputs, labels):\n",
    "    probabilities = torch.nn.Softmax(1)(outputs)\n",
    "    return probabilities[0, labels.item()].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sdataset(root / \"output\" / \"training_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ConvNet()\n",
    "net.cuda()\n",
    "criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "optimizer = optim.Adam(net.parameters(), lr=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "ax2 = ax.twinx()\n",
    "loss_ax = []\n",
    "accuracy_ax = []\n",
    "for epoch in range(10):\n",
    "    batch_generator = data.create_batch(100)\n",
    "    batch = batch_generator()\n",
    "    i=0\n",
    "    while batch is not None:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        labels, inputs = batch[0].squeeze(), batch[1]\n",
    "        labels, inputs = labels.cuda(), inputs.cuda()\n",
    "        \n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_ax += [loss.item()]\n",
    "        accuracy_ax += [batch_accuracy(outputs, labels)]\n",
    "        \n",
    "        ax.cla()\n",
    "        ax2.cla()\n",
    "        ax.plot(loss_ax)\n",
    "        ax.set_title(\"epoch %d, iter %d\"%(epoch, i))\n",
    "        ax.set_xlabel(\"Iteration number\")\n",
    "        ax.set_ylabel(\"CrossEntropyLoss\")\n",
    "        ax2.plot(accuracy_ax, color='red')\n",
    "        ax2.set_ylabel(\"Probability of correct answer\", color='red')\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "        \n",
    "        batch = batch_generator()\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sdataset(root / \"output\" / \"validation_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "net = ConvNet()\n",
    "net.load_state_dict(torch.load(root / \"saved_models\" / \"2020_09_07_3epochs\" / \"model\"))\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "accuracy_ax = []\n",
    "batch_generator = data.create_batch(1)\n",
    "batch = batch_generator()\n",
    "i=0\n",
    "while batch is not None:\n",
    "    labels, inputs = batch[0].squeeze(), batch[1]\n",
    "    labels, inputs = labels.cuda(), inputs.cuda()\n",
    "    outputs = net(inputs)\n",
    "\n",
    "    accuracy_ax += [accuracy(outputs, labels)]\n",
    "    ax.cla()\n",
    "    ax.plot(accuracy_ax, color='red')\n",
    "    ax.set_xlabel(\"Iteration number\")\n",
    "    ax.set_ylabel(\"Probability of correct answer\")\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "    batch = batch_generator()\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = predictdataset(root / \"data\" / \"002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv1d(1, 8, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv1d(8, 16, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv1d(16, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (output): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "net = ConvNet()\n",
    "net.load_state_dict(torch.load(root / \"saved_models\" / \"2020_09_07_3epochs\" / \"model\"))\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "005, 255\r"
     ]
    }
   ],
   "source": [
    "accuracy_ax = []\n",
    "n=256\n",
    "\n",
    "mask = np.zeros((n, n))\n",
    "for row in range(n):\n",
    "    for col in range(n):\n",
    "        inputs = data.tensor((row, col))\n",
    "        inputs = inputs.cuda()\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        probabilities = torch.nn.Softmax(1)(outputs)\n",
    "        result = torch.topk(probabilities, 1).indices\n",
    "        if result == 1:\n",
    "            mask[row, col] = 1\n",
    "        print(\"%03d, %03d\"%(row, col), end='\\r')\n",
    "    if row==5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x137988be400>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
